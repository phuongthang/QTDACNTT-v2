import numpy as np
import pickle
from pyvi import ViTokenizer
import re
from bs4 import BeautifulSoup

import string
import codecs

# Tá»« Ä‘iá»ƒn tÃ­ch cá»±c, tiÃªu cá»±c, phá»§ Ä‘á»‹nh
path_nag = "app/resources/sentiment_dict/nag.txt"
path_pos = "app/resources/sentiment_dict/pos.txt"
path_not = "app/resources/sentiment_dict/not.txt"
path_spos = "app/resources/sentiment_dict/spos.txt"
path_snot = "app/resources/sentiment_dict/snot.txt"

with codecs.open(path_nag, "r", encoding="UTF-8") as f:
    nag = f.readlines()
nag_list = [n.replace("\n", "") for n in nag]

with codecs.open(path_pos, "r", encoding="UTF-8") as f:
    pos = f.readlines()
pos_list = [n.replace("\n", "") for n in pos]
with codecs.open(path_not, "r", encoding="UTF-8") as f:
    not_ = f.readlines()
not_list = [n.replace("\n", "") for n in not_]

with codecs.open(path_spos, "r", encoding="UTF-8") as f:
    spos = f.readlines()
spos_list = [n.rstrip() for n in spos]

with codecs.open(path_snot, "r", encoding="UTF-8") as f:
    snot_ = f.readlines()
snot_list = [n.rstrip() for n in snot_]


def predict_lgr(model, text):
    pre_proba = model.predict_proba([text])[0]
    index = np.argmax(pre_proba)
    acc = str(round(pre_proba[index] * 100, 2))
    if index == 1:
        what = "positive"
    elif index == -1:
        what = "negative"
    else :
        what = "neutral"
    acc = str(acc) + "%"
    return acc, what


def load_model_lgr(filename="app/resources/trained_models/lr_model_huy.pkl"):
    classifier_filename_exp = filename
    with open(classifier_filename_exp, "rb") as infile:
        model = pickle.load(infile)
    return model


def load_model_svm(filename="app/resources/trained_models/svm_model.pkl"):
    classifier_filename_exp = filename
    with open(classifier_filename_exp, "rb") as infile:
        model = pickle.load(infile)
    return model


def predict_svm(model, text):
    predict = model.predict([text])[0]
    if predict == 1:
        label = "positive"
    elif predict == 0:
        label = "negative"
    else:
        label = "neutral"

    return label


def normalize_text(text):
    # Remove cÃ¡c kÃ½ tá»± kÃ©o dÃ i: vd: Ä‘áº¹ppppppp
    text = re.sub(
        r"([A-Z])\1+", lambda m: m.group(1).upper(), text, flags=re.IGNORECASE
    )

    # Chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng
    text = text.lower()

    # Chuáº©n hÃ³a tiáº¿ng Viá»‡t, xá»­ lÃ½ emoj, chuáº©n hÃ³a tiáº¿ng Anh, thuáº­t ngá»¯
    replace_list = {
        "Ã²a": "oÃ ",
        "Ã³a": "oÃ¡",
        "á»a": "oáº£",
        "Ãµa": "oÃ£",
        "á»a": "oáº¡",
        "Ã²e": "oÃ¨",
        "Ã³e": "oÃ©",
        "á»e": "oáº»",
        "Ãµe": "oáº½",
        "á»e": "oáº¹",
        "Ã¹y": "uá»³",
        "Ãºy": "uÃ½",
        "á»§y": "uá»·",
        "Å©y": "uá»¹",
        "á»¥y": "uá»µ",
        "uáº£": "á»§a",
        "aÌ‰": "áº£",
        "Ã´Ì": "á»‘",
        "uÂ´": "á»‘",
        "Ã´Ìƒ": "á»—",
        "Ã´Ì€": "á»“",
        "Ã´Ì‰": "á»•",
        "Ã¢Ì": "áº¥",
        "Ã¢Ìƒ": "áº«",
        "Ã¢Ì‰": "áº©",
        "Ã¢Ì€": "áº§",
        "oÌ‰": "á»",
        "ÃªÌ€": "á»",
        "ÃªÌƒ": "á»…",
        "ÄƒÌ": "áº¯",
        "uÌ‰": "á»§",
        "ÃªÌ": "áº¿",
        "Æ¡Ì‰": "á»Ÿ",
        "iÌ‰": "á»‰",
        "eÌ‰": "áº»",
        "Ã k": u" Ã  ",
        "aË‹": "Ã ",
        "iË‹": "Ã¬",
        "ÄƒÂ´": "áº¯",
        "Æ°Ì‰": "á»­",
        "eËœ": "áº½",
        "yËœ": "á»¹",
        "aÂ´": "Ã¡",
        # Quy cÃ¡c icon vá» 2 loáº¡i emoj: TÃ­ch cá»±c hoáº·c tiÃªu cá»±c
        "ğŸ‘¹": "nagative",
        "ğŸ‘»": "positive",
        "ğŸ’ƒ": "positive",
        "ğŸ¤™": " positive ",
        "ğŸ‘": " positive ",
        "ğŸ’„": "positive",
        "ğŸ’": "positive",
        "ğŸ’©": "positive",
        "ğŸ˜•": "nagative",
        "ğŸ˜±": "nagative",
        "ğŸ˜¸": "positive",
        "ğŸ˜¾": "nagative",
        "ğŸš«": "nagative",
        "ğŸ¤¬": "nagative",
        "ğŸ§š": "positive",
        "ğŸ§¡": "positive",
        "ğŸ¶": " positive ",
        "ğŸ‘": " nagative ",
        "ğŸ˜£": " nagative ",
        "âœ¨": " positive ",
        "â£": " positive ",
        "â˜€": " positive ",
        "â™¥": " positive ",
        "ğŸ¤©": " positive ",
        "like": " positive ",
        "ğŸ’Œ": " positive ",
        "ğŸ¤£": " positive ",
        "ğŸ–¤": " positive ",
        "ğŸ¤¤": " positive ",
        ":(": " nagative ",
        "ğŸ˜¢": " nagative ",
        "â¤": " positive ",
        "ğŸ˜": " positive ",
        "ğŸ˜˜": " positive ",
        "ğŸ˜ª": " nagative ",
        "ğŸ˜Š": " positive ",
        "?": " ? ",
        "ğŸ˜": " positive ",
        "ğŸ’–": " positive ",
        "ğŸ˜Ÿ": " nagative ",
        "ğŸ˜­": " nagative ",
        "ğŸ’¯": " positive ",
        "ğŸ’—": " positive ",
        "â™¡": " positive ",
        "ğŸ’œ": " positive ",
        "ğŸ¤—": " positive ",
        "^^": " positive ",
        "ğŸ˜¨": " nagative ",
        "â˜º": " positive ",
        "ğŸ’‹": " positive ",
        "ğŸ‘Œ": " positive ",
        "ğŸ˜–": " nagative ",
        "ğŸ˜€": " positive ",
        ":((": " nagative ",
        "ğŸ˜¡": " nagative ",
        "ğŸ˜ ": " nagative ",
        "ğŸ˜’": " nagative ",
        "ğŸ™‚": " positive ",
        "ğŸ˜": " nagative ",
        "ğŸ˜": " positive ",
        "ğŸ˜„": " positive ",
        "ğŸ˜™": " positive ",
        "ğŸ˜¤": " nagative ",
        "ğŸ˜": " positive ",
        "ğŸ˜†": " positive ",
        "ğŸ’š": " positive ",
        "âœŒ": " positive ",
        "ğŸ’•": " positive ",
        "ğŸ˜": " nagative ",
        "ğŸ˜“": " nagative ",
        "ï¸ğŸ†—ï¸": " positive ",
        "ğŸ˜‰": " positive ",
        "ğŸ˜‚": " positive ",
        ":v": "  positive ",
        "=))": "  positive ",
        "ğŸ˜‹": " positive ",
        "ğŸ’“": " positive ",
        "ğŸ˜": " nagative ",
        ":3": " positive ",
        "ğŸ˜«": " nagative ",
        "ğŸ˜¥": " nagative ",
        "ğŸ˜ƒ": " positive ",
        "ğŸ˜¬": " ğŸ˜¬ ",
        "ğŸ˜Œ": " ğŸ˜Œ ",
        "ğŸ’›": " positive ",
        "ğŸ¤": " positive ",
        "ğŸˆ": " positive ",
        "ğŸ˜—": " positive ",
        "ğŸ¤”": " nagative ",
        "ğŸ˜‘": " nagative ",
        "ğŸ”¥": " nagative ",
        "ğŸ™": " nagative ",
        "ğŸ†—": " positive ",
        "ğŸ˜»": " positive ",
        "ğŸ’™": " positive ",
        "ğŸ’Ÿ": " positive ",
        "ğŸ˜š": " positive ",
        "âŒ": " nagative ",
        "ğŸ‘": " positive ",
        ";)": " positive ",
        "<3": " positive ",
        "ğŸŒ": " positive ",
        "ğŸŒ·": " positive ",
        "ğŸŒ¸": " positive ",
        "ğŸŒº": " positive ",
        "ğŸŒ¼": " positive ",
        "ğŸ“": " positive ",
        "ğŸ…": " positive ",
        "ğŸ¾": " positive ",
        "ğŸ‘‰": " positive ",
        "ğŸ’": " positive ",
        "ğŸ’": " positive ",
        "ğŸ’¥": " positive ",
        "ğŸ’ª": " positive ",
        "ğŸ’°": " positive ",
        "ğŸ˜‡": " positive ",
        "ğŸ˜›": " positive ",
        "ğŸ˜œ": " positive ",
        "ğŸ™ƒ": " positive ",
        "ğŸ¤‘": " positive ",
        "ğŸ¤ª": " positive ",
        "â˜¹": " nagative ",
        "ğŸ’€": " nagative ",
        "ğŸ˜”": " nagative ",
        "ğŸ˜§": " nagative ",
        "ğŸ˜©": " nagative ",
        "ğŸ˜°": " nagative ",
        "ğŸ˜³": " nagative ",
        "ğŸ˜µ": " nagative ",
        "ğŸ˜¶": " nagative ",
        "ğŸ™": " nagative ",
        # Chuáº©n hÃ³a 1 sá»‘ sentiment words/English words
        ":))": "  positive ",
        ":)": " positive ",
        "Ã´ kÃªi": " ok ",
        "okie": " ok ",
        " o kÃª ": " ok ",
        "okey": " ok ",
        "Ã´kÃª": " ok ",
        "oki": " ok ",
        " oke ": " ok ",
        " okay": " ok ",
        "okÃª": " ok ",
        " tks ": u" cÃ¡m Æ¡n ",
        "thks": u" cÃ¡m Æ¡n ",
        "thanks": u" cÃ¡m Æ¡n ",
        "ths": u" cÃ¡m Æ¡n ",
        "thank": u" cÃ¡m Æ¡n ",
        "â­": "star ",
        "*": "star ",
        "ğŸŒŸ": "star ",
        "ğŸ‰": u" positive ",
        "ko": u"khÃ´ng",
        "kg ": u" khÃ´ng ",
        "not": u" khÃ´ng ",
        u" kg ": u" khÃ´ng ",
        '"k ': u" khÃ´ng ",
        " kh ": u" khÃ´ng ",
        "kÃ´": u" khÃ´ng ",
        "hok": u" khÃ´ng ",
        " kp ": u" khÃ´ng pháº£i ",
        u" kÃ´ ": u" khÃ´ng ",
        '"ko ': u" khÃ´ng ",
        u" ko ": u" khÃ´ng ",
        u" k ": u" khÃ´ng ",
        "khong": u" khÃ´ng ",
        u" hok ": u" khÃ´ng ",
        "he he": " positive ",
        "hehe": " positive ",
        "hihi": " positive ",
        "haha": " positive ",
        "hjhj": " positive ",
        " lol ": " nagative ",
        " cc ": " nagative ",
        "cute": u" dá»… thÆ°Æ¡ng ",
        "huhu": " nagative ",
        " vs ": u" vá»›i ",
        "wa": " quÃ¡ ",
        "wÃ¡": u" quÃ¡",
        "j": u" gÃ¬ ",
        "â€œ": " ",
        " sz ": u" cá»¡ ",
        "size": u" cá»¡ ",
        u" Ä‘x ": u" Ä‘Æ°á»£c ",
        "dk": u" Ä‘Æ°á»£c ",
        "dc": u" Ä‘Æ°á»£c ",
        "Ä‘k": u" Ä‘Æ°á»£c ",
        "Ä‘c": u" Ä‘Æ°á»£c ",
        "authentic": u" chuáº©n chÃ­nh hÃ£ng ",
        u" aut ": u" chuáº©n chÃ­nh hÃ£ng ",
        u" auth ": u" chuáº©n chÃ­nh hÃ£ng ",
        "thick": u" positive ",
        "store": u" cá»­a hÃ ng ",
        "shop": u" cá»­a hÃ ng ",
        "sp": u" sáº£n pháº©m ",
        "gud": u" tá»‘t ",
        "god": u" tá»‘t ",
        "wel done": " tá»‘t ",
        "good": u" tá»‘t ",
        "gÃºt": u" tá»‘t ",
        "sáº¥u": u" xáº¥u ",
        "gut": u" tá»‘t ",
        u" tot ": u" tá»‘t ",
        u" nice ": u" tá»‘t ",
        "perfect": "ráº¥t tá»‘t",
        "bt": u" bÃ¬nh thÆ°á»ng ",
        "time": u" thá»i gian ",
        "qÃ¡": u" quÃ¡ ",
        u" ship ": u" giao hÃ ng ",
        u" m ": u" mÃ¬nh ",
        u" mik ": u" mÃ¬nh ",
        "ÃªÌ‰": "á»ƒ",
        "product": "sáº£n pháº©m",
        "quality": "cháº¥t lÆ°á»£ng",
        "chat": " cháº¥t ",
        "excelent": "hoÃ n háº£o",
        "bad": "tá»‡",
        "fresh": " tÆ°Æ¡i ",
        "sad": " tá»‡ ",
        "date": u" háº¡n sá»­ dá»¥ng ",
        "hsd": u" háº¡n sá»­ dá»¥ng ",
        "quickly": u" nhanh ",
        "quick": u" nhanh ",
        "fast": u" nhanh ",
        "delivery": u" giao hÃ ng ",
        u" sÃ­p ": u" giao hÃ ng ",
        "beautiful": u" Ä‘áº¹p tuyá»‡t vá»i ",
        u" tl ": u" tráº£ lá»i ",
        u" r ": u" rá»“i ",
        u" shopE ": u" cá»­a hÃ ng ",
        u" order ": u" Ä‘áº·t hÃ ng ",
        "cháº¥t lg": u" cháº¥t lÆ°á»£ng ",
        u" sd ": u" sá»­ dá»¥ng ",
        u" dt ": u" Ä‘iá»‡n thoáº¡i ",
        u" nt ": u" nháº¯n tin ",
        u" tl ": u" tráº£ lá»i ",
        u" sÃ i ": u" xÃ i ",
        u"bjo": u" bao giá» ",
        "thik": u" thÃ­ch ",
        u" sop ": u" cá»­a hÃ ng ",
        " fb ": " facebook ",
        " face ": " facebook ",
        " very ": u" ráº¥t ",
        u"quáº£ ng ": u" quáº£ng  ",
        "dep": u" Ä‘áº¹p ",
        u" xau ": u" xáº¥u ",
        "delicious": u" ngon ",
        u"hÃ g": u" hÃ ng ",
        u"qá»§a": u" quáº£ ",
        "iu": u" yÃªu ",
        "fake": u" giáº£ máº¡o ",
        "trl": "tráº£ lá»i",
        "><": u" positive ",
        " por ": u" tá»‡ ",
        " poor ": u" tá»‡ ",
        "ib": u" nháº¯n tin ",
        "rep": u" tráº£ lá»i ",
        u"fback": " feedback ",
        "fedback": " feedback ",
        # dÆ°á»›i 3* quy vá» 1*, trÃªn 3* quy vá» 5*
        "6 sao": " 5star ",
        "6 star": " 5star ",
        "5star": " 5star ",
        "5 sao": " 5star ",
        "5sao": " 5star ",
        "starstarstarstarstar": " 5star ",
        "1 sao": " 1star ",
        "1sao": " 1star ",
        "2 sao": " 1star ",
        "2sao": " 1star ",
        "1 star": "1star",
        "2 starstar": " 1star ",
        "1star": " 1star ",
        "0 sao": " 1star ",
        "0star": " 1star ",
    }

    for k, v in replace_list.items():
        text = text.replace(k, v)

    # chuyen punctuation thÃ nh space
    translator = str.maketrans(string.punctuation, " " * len(string.punctuation))
    text = text.translate(translator)
    text = re.sub(r"http\S+", "", text)
    text = BeautifulSoup(text, "lxml").get_text()
    text = re.sub("\S*\d\S*", "", text).strip()

    """
    str =  " Thá»i gian giao hÃ ng ráº¥t nhanh giÃ¡ ráº» mÃ  giÃ y cá»±c cháº¥t! ÃŠm chÃ¢n láº¯m.thanks shop nhiá»u" 
    text = ViTokenizer.tokenize(str) "Thá»i_gian giao hÃ ng ráº¥t nhanh giÃ¡ ráº» mÃ  giÃ y cá»±c cháº¥t ! ÃŠm chÃ¢n láº¯m . thanks shop nhiá»u" 
    texts = text.split() ['Thá»i_gian', 'giao', 'hÃ ng', 'ráº¥t', 'nhanh', 'giÃ¡', 'ráº»', 'mÃ ', 'giÃ y', 'cá»±c', 'cháº¥t', '!', 'ÃŠm', 'chÃ¢n', 'láº¯m', '.', 'thanks', 'shop', 'nhiá»u']
    texts = [t.replace('_', ' ') for t in texts] ['Thá»i gian', 'giao', 'hÃ ng', 'ráº¥t', 'nhanh', 'giÃ¡', 'ráº»', 'mÃ ', 'giÃ y', 'cá»±c', 'cháº¥t', '!', 'ÃŠm', 'chÃ¢n', 'láº¯m', '.', 'thanks', 'shop', 'nhiá»u']
    """
    text = ViTokenizer.tokenize(text)
    texts = text.split()
    len_text = len(texts)

    texts = [t.replace("_", " ") for t in texts]
    for i in range(len_text):
        cp_text = texts[i]
        if (
                cp_text in not_list
        ):  # Xá»­ lÃ½ váº¥n Ä‘á» phá»§ Ä‘á»‹nh (VD: Ã¡o nÃ y cháº³ng Ä‘áº¹p--> Ã¡o nÃ y notpos)
            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1

            for j in range(numb_word):
                if texts[i + j + 1] in pos_list:
                    texts[i] = "notpos"
                    texts[i + j + 1] = ""

                if texts[i + j + 1] in nag_list:
                    texts[i] = "notnag"
                    texts[i + j + 1] = ""
        else:  # ThÃªm feature cho nhá»¯ng sentiment words (Ã¡o nÃ y Ä‘áº¹p--> Ã¡o nÃ y Ä‘áº¹p positive)
            if cp_text in pos_list:
                texts.append("positive")
            elif cp_text in nag_list:
                texts.append("negative")

    text = u" ".join(texts)

    # remove ná»‘t nhá»¯ng kÃ½ tá»± thá»«a thÃ£i
    text = text.replace(u'"', u" ")
    text = text.replace(u"ï¸", u"")
    text = text.replace("ğŸ»", "")
    for pos in spos_list:
        if pos in text:
            text += " " + "positive"
    for snot in snot_list:
        if snot in text:
            text += " " + "negative"
    return text
